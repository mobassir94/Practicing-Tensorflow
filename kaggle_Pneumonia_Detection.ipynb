{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kaggle_Pneumonia_Detection.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mobassir94/Practicing-Tensorflow/blob/master/kaggle_Pneumonia_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ei99ZNdbUaFg",
        "colab_type": "text"
      },
      "source": [
        "**Importing Necessary Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HI0-u3rpUSOh",
        "colab_type": "code",
        "outputId": "d741a9aa-3b78-45cd-f10a-d684f21a8388",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Dense,GlobalAveragePooling2D\n",
        "from keras.applications import MobileNet\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.mobilenet import preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "from keras import optimizers\n",
        "from google.colab import files\n",
        "\n",
        "from glob import glob\n",
        "import os\n",
        "import numpy as np\n",
        "#import pandas as pd\n",
        "import tensorflow as tf\n",
        "#from skimage.io import imread\n",
        "\n",
        "#import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from tensorflow.python.keras.applications import ResNet50\n",
        "from tensorflow.python.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "from tensorflow.python.keras.applications import ResNet50\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D, BatchNormalization\n",
        "from tensorflow.python.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.python.keras.preprocessing.image import load_img, img_to_array\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PtcFk0HVHXn",
        "colab_type": "text"
      },
      "source": [
        "**Below Code is going to download the \"Chest X-Ray Images (Pneumonia)\" dataset for us from kaggle.before running the cell below follow this stackoverflow questions accepted answer [ here](https://stackoverflow.com/questions/49310470/using-kaggle-datasets-in-google-colab) to get the kaggle.json file.once you have the json file on your local machine,run the code below and upload the json file there**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnrMrNpnUhf0",
        "colab_type": "code",
        "outputId": "e8c87604-11fa-4270-a4f8-50de95b58199",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "!pip install -U -q kaggle\n",
        "!mkdir  /root/.kaggle\n",
        "\n",
        "files.upload()\n",
        "!cp kaggle.json /root/.kaggle\n",
        "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c1f8559a-6a9d-4a55-881d-310a2a9a9eef\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-c1f8559a-6a9d-4a55-881d-310a2a9a9eef\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading chest-xray-pneumonia.zip to /content\n",
            "100% 1.15G/1.15G [00:08<00:00, 154MB/s]\n",
            "100% 1.15G/1.15G [00:08<00:00, 146MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5H2mlt-X6NR",
        "colab_type": "text"
      },
      "source": [
        "**COOL!! now we've downloaded the dataset,but the dataset is currently zipped and we have to unzip it before we can use the dataset,the code written in the cell below is going to do exactly that,it is going to unzip our zipped dataset and delete the zipped dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GUHYlYfXqtw",
        "colab_type": "code",
        "outputId": "06144fb0-d01f-49af-cfca-d1349f512435",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!apt install pv\n",
        "!unzip -o /content/chest-xray-pneumonia.zip  | pv -l >/dev/null\n",
        "os.remove('chest-xray-pneumonia.zip')\n",
        "!unzip -o /content/chest_xray.zip  | pv -l >/dev/null\n",
        "os.remove('chest_xray.zip')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "pv is already the newest version (1.6.6-1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded.\n",
            "2.00  0:00:09 [ 206m/s] [  <=>                                                 ]\n",
            "11.8k 0:00:14 [ 809 /s] [               <=>                                    ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiz9GFY7Yh2b",
        "colab_type": "text"
      },
      "source": [
        "Now we will try to apply two machine learning model here in this notebook and will pick the best machine learning model.\n",
        "\n",
        "# Model - 1 : RESNET50(keras)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXEX6I6Bbf6-",
        "colab_type": "text"
      },
      "source": [
        "*download the resnet50 weight file from this [link](https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5)  and upload this file in google colab by expanding your file manager panel then click on \"Files\" tab and then click on UPLOAD and then select the 'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5' file from your hard drive and upload that in your notebook. now execute the cell below*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdYdSDWDYWJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 2 #Dataset has 2 class 1.NORMAL and 2.PNEUMONIA\n",
        "\n",
        "\n",
        "#our resnet50's weight file is inside '/content/' directory\n",
        "\n",
        "resnet_weights_path = '/content/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5' \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RtIEDuscs9H",
        "colab_type": "text"
      },
      "source": [
        "**Making the RESNET50 Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyoNuUShdg5F",
        "colab_type": "text"
      },
      "source": [
        "*As because the fully connected layers at the end can only take fixed size inputs, which has been previously defined by the input shape and all processing in the convolutional layers. Any change to the input shape will change the shape of the input to the fully connected layers we are going to drop the fuly connected layers  using \"include_top = False\" from resnet50 weight file and adding our own model in that place\n",
        "\n",
        "batch normalization allows each layer of a network to learn by itself a little bit more independently of other layers.we know deep neural networks typically meets the problem called \"gradient vanishing problem\" hence By using BatchNormalization() we are normalizing the output of neurons, the activation function will only receive inputs close to zero. This ensures a non-vanishing gradient.\n",
        "\n",
        "and it works like this [Example](https://cdn-images-1.medium.com/max/2100/1*VTNB7oSbyaxtIpZ3kXdH4A.png)\n",
        "\n",
        "so at the end of resnet50 model what we are doing in the below cell are following :\n",
        "\n",
        "1.we are creating a Sequential model by passing a list of layer instances to the constructor (The Sequential model is a linear stack of layers.)\n",
        "\n",
        "2. we are disconnecting fully connected layers by saying \"include_top = False\" \n",
        "\n",
        "\n",
        "3.in place of disconnected fully connected layers we are adding Flatten() layer which basically takes the previous layer and converts it from n-d tensor to one giant 1-d tensor.\n",
        "\n",
        "4.on top of Flatten() we are adding BatchNormalization() layer (as discussed above about it's importance)\n",
        "\n",
        "5.on top of BatchNormalization() we are adding Dense() layer which is taking the Flatten() layer as input and applying 'relu' activation to produce 2048 outputs.\n",
        "\n",
        "6.on top of Dense() layer which produces 2048 outputs,we are again adding BatchNormalization() to normalize the features\n",
        "\n",
        "7.again adding one more Dense() layer which applies 'relu' activation on previously  normalized 2048 outputs and produces new 1024 outputs for the next layer\n",
        "\n",
        "8.again applying BatchNormalization() and to normalize the new features\n",
        "\n",
        "9.again adding one more Dense() layer which applies 'relu' activation on previously  normalized 1024 outputs and produces new 512 outputs for the next layer\n",
        "\n",
        "10.again applying BatchNormalization()  to normalize the new features\n",
        "\n",
        "11.again adding one more Dense() layer which applies 'relu' activation on previously  normalized 512 outputs and produces new 256 outputs for the next layer\n",
        "\n",
        "12.applying BatchNormalization for the last time to normalize our features.\n",
        "\n",
        "13.applying final Dense() layer which applies softmax activation on previous layers 256 normalized outputs and produces 2 outputs which are basically probability for 'NORMAL' and 'PNEUMONIA' class\n",
        "\n",
        "14.now we will train every layer except the first layer so we say 'model.layers[0].trainable = False'\n",
        "\n",
        "\n",
        "*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkW3SnwpchWI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.layers import Dense, GlobalMaxPooling2D\n",
        "model = Sequential()\n",
        "model.add(ResNet50(include_top=False, pooling='avg', weights=resnet_weights_path))\n",
        "\n",
        "'''#model.add(Dense(num_classes, activation='softmax'))\n",
        "model.add(Flatten())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(2048, activation='relu'))\n",
        "#model.add(Dropout(0.3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "#model.add(Dropout(0.3))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(num_classes, activation='softmax'))'''\n",
        "from tensorflow.python.keras.optimizers import Adam\n",
        "\n",
        "model.layers[0].trainable = False\n",
        "\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6uD_w4bs3HN",
        "colab_type": "text"
      },
      "source": [
        "**Data Directories**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RSHj2dSsIPE",
        "colab_type": "code",
        "outputId": "6755395d-13ee-49c7-9040-45754517e9d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Path to data\n",
        "data_dir  = '/content/chest_xray/'\n",
        "train_dir = data_dir+'train/'\n",
        "test_dir  = data_dir+'test/'\n",
        "val_dir   = data_dir + 'val/'\n",
        "\n",
        "\n",
        "\n",
        "# Get the path to the normal and pneumonia sub-directories\n",
        "normal_cases_dir = train_dir + 'NORMAL/'\n",
        "pneumonia_cases_dir = train_dir + 'PNEUMONIA/'\n",
        "\n",
        "print(\"Datasets:\\t\",os.listdir(data_dir))\n",
        "print(\"Train:\\t\", os.listdir(train_dir))\n",
        "print(\"Test:\\t\", os.listdir(test_dir))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Datasets:\t ['.DS_Store', 'test', 'train', 'val']\n",
            "Train:\t ['.DS_Store', 'PNEUMONIA', 'NORMAL']\n",
            "Test:\t ['.DS_Store', 'PNEUMONIA', 'NORMAL']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtOyZPwbtHKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "image_size = 150 #The default input size for this model is 224x224.\n",
        "nb_train_samples = 5216 # number of files in training set\n",
        "num_of_test_samples = 624 # number of files in test set\n",
        "batch_size = 16 #the model will take 16 random batches of files at a time during training\n",
        "\n",
        "EPOCHS = 6 #we will run this model for 20 epochs(1 epoch = whole dataset traversion during training)\n",
        "STEPS = nb_train_samples // batch_size #the model will take 326 steps to complete per batch training"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZq884cqwFlM",
        "colab_type": "text"
      },
      "source": [
        "The preprocess_input function is meant to adequate your image to the format the model requires. You don't need to worry about the internal details of preprocess_input. But ideally, you should load images with the keras functions for that (so you guarantee that the images you load are compatible with preprocess_input). \n",
        "\n",
        "@keras_modules_injection\n",
        "\n",
        "\n",
        "def preprocess_input(*args, **kwargs):\n",
        "    \n",
        "    return imagenet_utils.preprocess_input(*args, **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1MDOu88t4I8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "## Specify the values for all arguments to data_generator_with_aug.\n",
        "data_generator_with_aug = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
        "                                            \n",
        "                                             horizontal_flip = True,\n",
        "                                             width_shift_range = 0.2,\n",
        "                                             height_shift_range = 0.2,\n",
        "                                             shear_range = 0.2,\n",
        "                                             zoom_range = 0.2\n",
        "                                            )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MbVqlxyt-Tw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_generator_no_aug = ImageDataGenerator(preprocessing_function=preprocess_input            \n",
        "                                          )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGCAb4GJw0Jw",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "1.in 'train_generator' We are going to apply augmentation on training dataset and flow_from_directory is helping us to collect data from train directory where target size is 224x224 and batch size=16(as we defined above) and class_mode = 'categorical' as we have 2 classes 'NORMAL' and 'PNEUMONIA' which are 2 categories\n",
        "\n",
        "2.'validation_generator' and 'test_generator' both are same as train_generator except 2 things which are : we don't have batch_size  for 'validation_generator' because keras will do it by default for our 16 validation images and we are applying no image augmentation techniques both in 'validation_generator' and 'test_generator'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4uLS_pvuCcS",
        "colab_type": "code",
        "outputId": "4699bc48-06ca-4b18-bdd6-38b0d9b2c76f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "\n",
        "  \n",
        "train_generator = data_generator_with_aug.flow_from_directory(\n",
        "       directory = train_dir,\n",
        "       target_size = (image_size, image_size),\n",
        "       batch_size = batch_size,\n",
        "       class_mode = 'categorical')\n",
        "\n",
        "validation_generator = data_generator_no_aug.flow_from_directory(\n",
        "       directory = val_dir,\n",
        "       target_size = (image_size, image_size), \n",
        "       class_mode = 'categorical')\n",
        "\n",
        "test_generator = data_generator_no_aug.flow_from_directory(\n",
        "       directory = test_dir,\n",
        "       target_size = (image_size, image_size),\n",
        "       batch_size = batch_size,\n",
        "       class_mode = 'categorical')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5216 images belonging to 2 classes.\n",
            "Found 16 images belonging to 2 classes.\n",
            "Found 624 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8S3olMtczSd2",
        "colab_type": "text"
      },
      "source": [
        "**Fitting the model with training set,defined EPOCHS,step size,validation data and validation_steps**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81QYvu3KzGbS",
        "colab_type": "code",
        "outputId": "88230421-2b29-4855-b61c-2ae89f2e6336",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "source": [
        "#model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history = model.fit_generator(\n",
        "       train_generator, # specify where model gets training data\n",
        "       epochs = EPOCHS,\n",
        "       steps_per_epoch=STEPS,\n",
        "       validation_data=validation_generator,\n",
        "       \n",
        "       ) # specify where model gets validation data\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "1/1 [==============================] - 0s 361ms/step - loss: 0.2304 - acc: 0.8750\n",
            "326/326 [==============================] - 122s 374ms/step - loss: 0.1172 - acc: 0.9515 - val_loss: 0.2304 - val_acc: 0.8750\n",
            "Epoch 2/6\n",
            "1/1 [==============================] - 0s 326ms/step - loss: 0.2142 - acc: 0.8750\n",
            "326/326 [==============================] - 121s 370ms/step - loss: 0.1125 - acc: 0.9584 - val_loss: 0.2142 - val_acc: 0.8750\n",
            "Epoch 3/6\n",
            "1/1 [==============================] - 0s 349ms/step - loss: 0.2939 - acc: 0.8750\n",
            "326/326 [==============================] - 121s 370ms/step - loss: 0.1071 - acc: 0.9549 - val_loss: 0.2939 - val_acc: 0.8750\n",
            "Epoch 4/6\n",
            "1/1 [==============================] - 0s 331ms/step - loss: 0.3183 - acc: 0.8125\n",
            "326/326 [==============================] - 121s 372ms/step - loss: 0.0967 - acc: 0.9638 - val_loss: 0.3183 - val_acc: 0.8125\n",
            "Epoch 5/6\n",
            "1/1 [==============================] - 0s 385ms/step - loss: 0.2128 - acc: 0.8750\n",
            "326/326 [==============================] - 119s 364ms/step - loss: 0.1041 - acc: 0.9588 - val_loss: 0.2128 - val_acc: 0.8750\n",
            "Epoch 6/6\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 0.2024 - acc: 0.9375\n",
            "326/326 [==============================] - 122s 375ms/step - loss: 0.0985 - acc: 0.9601 - val_loss: 0.2024 - val_acc: 0.9375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tkSQjIl4VYS",
        "colab_type": "code",
        "outputId": "f85e0947-07dd-47e4-a492-902c756f2ba9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        }
      },
      "source": [
        "\n",
        "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "t = f.suptitle('vgg16 Performance', fontsize=12)\n",
        "f.subplots_adjust(top=0.85, wspace=0.3)\n",
        "\n",
        "epoch_list = list(range(1,11))\n",
        "ax1.plot(epoch_list, history.history['acc'], label='Train Accuracy')\n",
        "ax1.plot(epoch_list, history.history['val_acc'], label='Validation Accuracy')\n",
        "ax1.set_xticks(np.arange(0, 11, 5))\n",
        "ax1.set_ylabel('Accuracy Value')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_title('Accuracy')\n",
        "l1 = ax1.legend(loc=\"best\")\n",
        "\n",
        "ax2.plot(epoch_list, history.history['loss'], label='Train Loss')\n",
        "ax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')\n",
        "ax2.set_xticks(np.arange(0, 11, 5))\n",
        "ax2.set_ylabel('Loss Value')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_title('Loss')\n",
        "l2 = ax2.legend(loc=\"best\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-804a31a7710e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mepoch_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1612\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 231\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (10,) and (6,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsoAAAEVCAYAAAD5FsMnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKwyLTfzFjn9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hvqor1dzoFH",
        "colab_type": "code",
        "outputId": "38edb022-d0ad-45a8-d055-d84434551b91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "# Evaluate the model\n",
        "scores = model.evaluate_generator(test_generator)\n",
        "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "\n",
        "scores = model.evaluate_generator(test_generator) #624 testing images\n",
        "print(\"Test Accuracy = \", scores[1])\n",
        "\n",
        "scores = model.evaluate_generator(validation_generator) #16 validation images\n",
        "print(\"validation Accuracy = \", scores[1])\n",
        "\n",
        "#scores = model.predict_generator(test_generator) #624 testing images\n",
        "#print(\"first prediction = \", scores[0])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "acc: 89.74%\n",
            "Test Accuracy =  0.8974359\n",
            "validation Accuracy =  0.875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5OT2P7WG7RO",
        "colab_type": "text"
      },
      "source": [
        "**Confution Matrix and Classification Report**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLhEMDo3HC7n",
        "colab_type": "code",
        "outputId": "8d978572-bd91-4709-9f94-27e2034371d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "Y_pred = model.predict_generator(test_generator, num_of_test_samples // batch_size+1)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(test_generator.classes, y_pred))\n",
        "print('Classification Report')\n",
        "target_names = ['NORMAL', 'PNEUMONIA']\n",
        "print(classification_report(test_generator.classes, y_pred, target_names=target_names))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix\n",
            "[[ 78 156]\n",
            " [130 260]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      NORMAL       0.38      0.33      0.35       234\n",
            "   PNEUMONIA       0.62      0.67      0.65       390\n",
            "\n",
            "   micro avg       0.54      0.54      0.54       624\n",
            "   macro avg       0.50      0.50      0.50       624\n",
            "weighted avg       0.53      0.54      0.54       624\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpxKP6w58KmQ",
        "colab_type": "text"
      },
      "source": [
        "**Lets try to do something funky,we will change our previous model with some convolutional layers,pooling layers and dropouts as below and see if it does better than the previous one or not**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyFR_dBfzsqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import os\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import fnmatch\n",
        "import keras\n",
        "from time import sleep\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Conv2D,MaxPool2D,Dropout,Flatten,BatchNormalization,MaxPooling2D,Activation\n",
        "from keras.optimizers import RMSprop,Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from keras import backend as k\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(ResNet50(include_top=False, pooling='avg', weights=resnet_weights_path))\n",
        "\n",
        "model.add(Conv2D(32,(7,7),activation='relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.15))\n",
        "model.add(Conv2D(64,(5,5),activation='relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.15))\n",
        "model.add(Conv2D(128,(3,3),activation='relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.15))\n",
        "model.add(Conv2D(128,(3,3),activation='relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.15))\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(1000, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "model.layers[0].trainable = False\n",
        "model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaonZgec8suW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit_generator(\n",
        "       train_generator, # specify where model gets training data\n",
        "       epochs = EPOCHS,\n",
        "       steps_per_epoch=STEPS,\n",
        "       validation_data=validation_generator,\n",
        "       validation_steps=num_of_test_samples // batch_size,\n",
        "       ) # specify where model gets validation data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gr_shMTSKpah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ulf1r10BKqsN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}